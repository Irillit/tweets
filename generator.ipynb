{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bacc1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tegua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "UNKNOWN = \"<UNK>\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "NUMBER = \"NUM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434dd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus():\n",
    "    tweets = pd.read_csv('tweets.csv')\n",
    "    tweets = tweets['content']\n",
    "    print('The shape of tweets: {}'.format(tweets.size))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8561778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of tweets: 41122\n"
     ]
    }
   ],
   "source": [
    "tweets_corpus = get_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0758b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Be sure to tune in and watch Donald Trump on L...\n",
       "1    Donald Trump will be appearing on The View tom...\n",
       "2    Donald Trump reads Top Ten Financial Tips on L...\n",
       "3    New Blog Post: Celebrity Apprentice Finale and...\n",
       "4    \"My persona will never be that of a wallflower...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cedea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(tweets):\n",
    "    tokenized_sentences = []\n",
    "    all_words = []\n",
    "\n",
    "    def tokenize(tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\n",
    "        tweet = re.sub(r\"[^a-zA-Z0-9.?! ]+\", \"\", tweet)\n",
    "        tweet = re.sub(r\"[0-9]+\", NUMBER, tweet)\n",
    "        tweet = tweet.replace(\"!\", \".\")\n",
    "        sentences = tweet.split(\".\")\n",
    "        for sentence in sentences:\n",
    "            tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "            if len(tokenized_sentence) > 0:\n",
    "                tokenized_sentences.append(tokenized_sentence)\n",
    "                all_words.extend(tokenized_sentence)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        tokenize(tweet)\n",
    "    \n",
    "    return tokenized_sentences, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328f270c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences, all_words = tokenize_sentences(tweets_corpus)\n",
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61af4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_unigrams(all_words):\n",
    "    unigram_map = Counter(all_words)\n",
    "    filtered_unigrams = {x: count for x, count in unigram_map.items() if count > 2}\n",
    "    \n",
    "    return filtered_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6735db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = get_filtered_unigrams(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b0b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_unk(sentences, unigrams):\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            if not sentence[i] in unigrams:\n",
    "                sentence[i] = UNKNOWN\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8967333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = replace_with_unk(tokenized_sentences, unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0c1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(sentences):\n",
    "    bigram_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = tuple([START_TOKEN] + sentence + [END_TOKEN])\n",
    "        for i in range(len(sentence) - 1):\n",
    "            bigram = sentence[i: i+2]\n",
    "            bigram_list.append(bigram)\n",
    "    bigram_map = Counter(bigram_list)\n",
    "    return dict(bigram_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88e119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = generate_bigrams(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2fa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_probability(word, prev, unigrams, bigrams):\n",
    "    k = 1.0\n",
    "    size = len(bigrams)\n",
    "    \n",
    "    prev_count = unigrams.get(prev, 0)\n",
    "    denominator = prev_count + k * size\n",
    "    \n",
    "    ngram = (prev, word)\n",
    "    ngram_count = bigrams.get(ngram, 0)\n",
    "    numerator = ngram_count + k\n",
    "    \n",
    "    probability = numerator / denominator\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4575645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(prev, unigrams, bigrams):\n",
    "    probabilities = {}\n",
    "    vocab = list(unigrams.keys()) + [START_TOKEN, END_TOKEN, UNKNOWN]\n",
    "    for word in vocab:\n",
    "        probability = estimate_probability(word, prev, unigrams, bigrams)\n",
    "        probabilities[word] = probability\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07838822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_word(prev_token, unigrams, bigrams):\n",
    "    suggestion = None\n",
    "    max_prob = 0\n",
    "    probs = get_probabilities(prev_token, unigrams, bigrams)   \n",
    "    \n",
    "    for word, prob in probs.items():\n",
    "        if prob > max_prob: \n",
    "            suggestion = word\n",
    "            max_prob = prob\n",
    "    return suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3406804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_n_words(prev_token, unigrams, bigrams, n):\n",
    "    max_prob = 0\n",
    "    probs = get_probabilities(prev_token, unigrams, bigrams)\n",
    "    suggestions = {}\n",
    "    heap = []\n",
    "    for word, prob in probs.items():\n",
    "        if word != UNKNOWN:\n",
    "            threshhold = heapq.nsmallest(1, heap)\n",
    "            if len(threshhold) == 0 or prob > threshhold[0]: \n",
    "                if len(heap) >= 3:\n",
    "                    key = heapq.heappop(heap)\n",
    "                    try:\n",
    "                        del suggestions[key]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                heapq.heappush(heap, prob)\n",
    "                suggestions[prob] = word\n",
    "    \n",
    "    return random.choice(list(suggestions.values())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606f9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_sentence(generated_list):\n",
    "    if len(generated_list) > 0:\n",
    "        generated_list[0] = generated_list[0].capitalize()\n",
    "    return \" \".join(generated_list) + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43b5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(initial_word):\n",
    "    word = initial_word\n",
    "    generated = []\n",
    "    \n",
    "    while word != END_TOKEN:\n",
    "        if word == NUMBER:\n",
    "            word = str(random.randint(1, 3000))\n",
    "        if word == \"NUMpm\":\n",
    "            word = str(random.randint(1, 12)) + \"pm\"\n",
    "        generated.append(word)\n",
    "        word = suggest_n_words(word, unigrams, bigrams, 5)\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa80ab6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = generate_sentence('i')\n",
    "format_to_sentence(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdf731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
